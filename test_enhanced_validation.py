#!/usr/bin/env python3
"""
Test script for enhanced validation that filters out timestamps and headers
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.services import ocr_service

def test_validation_filtering():
    """Test that the enhanced validation properly filters out non-metric content."""
    
    print("ğŸ” Testing Enhanced Validation Filtering")
    print("=" * 60)
    
    # Test cases that should be REJECTED (not treated as metrics)
    should_reject = [
        # Timestamps and dates
        "26.04.2025: 16:12",
        "14: 19",
        "Ğ”Ğ°Ñ‚Ğ°: 26.04.2025",
        "Ğ’Ñ€ĞµĞ¼Ñ: 16:12",
        "26.04.2025_16: 12",
        
        # Section headers
        "Ğ›Ğ¸Ğ¼Ñ„Ğ¾Ñ†Ğ¸Ñ‚Ñ‹ (Ğ°Ğ±Ñ: ĞºĞ¾Ğ»-Ğ²Ğ¾)",
        "ĞĞ±Ñ‰Ğ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·: ĞºÑ€Ğ¾Ğ²Ğ¸",
        "Ğ‘Ğ¸Ğ¾Ñ…Ğ¸Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹: Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·",
        "ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»Ğ¸: Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ",
        "Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹: Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°",
        
        # Invalid structures
        "ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ: Ğ±ĞµĞ· Ñ‡Ğ¸ÑĞ»Ğ¾Ğ²Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…",
        "ĞšĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¹: Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ",
        "Ğ—Ğ°ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ: Ğ² Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ°Ñ… Ğ½Ğ¾Ñ€Ğ¼Ñ‹",
        
        # Values without proper units
        "Ğ¢ĞµÑÑ‚: 123",
        "Ğ—Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ: Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‡Ğ¸ÑĞ»Ğ¾",
    ]
    
    # Test cases that should be ACCEPTED (treated as metrics)
    should_accept = [
        # Valid metrics with standard units
        "HGB: 163.00 Ğ³/Ğ» (Ğ½Ğ¾Ñ€Ğ¼Ğ°: 130,00 - 160,00)",
        "MCV: 83.20 Ñ„Ğ» (Ğ½Ğ¾Ñ€Ğ¼Ğ°: 80,00 - 100,00)",
        "RDW: 12.60 % (Ğ½Ğ¾Ñ€Ğ¼Ğ°: 11,50 - 14,50)",
        
        # Valid metrics with scientific notation
        "RBC: 5.66 10^12/Ğ» (Ğ½Ğ¾Ñ€Ğ¼Ğ°: 4,50 - 5,90)",
        "PLT: 319.00 10^9/Ğ» (Ğ½Ğ¾Ñ€Ğ¼Ğ°: 180,00 - 320,00)",
        "WBC: 6.37 10^9/Ğ» (Ğ½Ğ¾Ñ€Ğ¼Ğ°: 4,00 - 9,00)",
        
        # Valid metrics with different formats
        "Ğ“Ğ»ÑĞºĞ¾Ğ·Ğ°: 5.2 Ğ¼Ğ¼Ğ¾Ğ»ÑŒ/Ğ»",
        "Ğ¥Ğ¾Ğ»ĞµÑÑ‚ĞµÑ€Ğ¸Ğ½: 4.8 Ğ¼Ğ¼Ğ¾Ğ»ÑŒ/Ğ»",
        "ĞšÑ€ĞµĞ°Ñ‚Ğ¸Ğ½Ğ¸Ğ½: 85 Ğ¼ĞºĞ¼Ğ¾Ğ»ÑŒ/Ğ»",
    ]
    
    print("ğŸš« Testing REJECTION of non-metric content:")
    print("-" * 50)
    
    rejection_success = 0
    for test_case in should_reject:
        try:
            metrics = ocr_service.extract_metrics_from_text(test_case)
            if len(metrics) == 0:
                print(f"âœ… CORRECTLY REJECTED: {test_case}")
                rejection_success += 1
            else:
                print(f"âŒ INCORRECTLY ACCEPTED: {test_case}")
                for metric in metrics:
                    print(f"   â†’ {metric['name']} = {metric['value']} {metric['unit']}")
        except Exception as e:
            print(f"âŒ ERROR with: {test_case} - {e}")
    
    print(f"\nğŸ“Š Rejection Success Rate: {rejection_success}/{len(should_reject)} ({rejection_success/len(should_reject)*100:.1f}%)")
    
    print("\nâœ… Testing ACCEPTANCE of valid metrics:")
    print("-" * 50)
    
    acceptance_success = 0
    for test_case in should_accept:
        try:
            metrics = ocr_service.extract_metrics_from_text(test_case)
            if len(metrics) > 0:
                print(f"âœ… CORRECTLY ACCEPTED: {test_case}")
                for metric in metrics:
                    print(f"   â†’ {metric['name']} = {metric['value']} {metric['unit']} (conf: {metric.get('confidence', 0):.2f})")
                acceptance_success += 1
            else:
                print(f"âŒ INCORRECTLY REJECTED: {test_case}")
        except Exception as e:
            print(f"âŒ ERROR with: {test_case} - {e}")
    
    print(f"\nğŸ“Š Acceptance Success Rate: {acceptance_success}/{len(should_accept)} ({acceptance_success/len(should_accept)*100:.1f}%)")
    
    # Overall assessment
    overall_success = (rejection_success == len(should_reject)) and (acceptance_success == len(should_accept))
    
    print(f"\nğŸ¯ OVERALL VALIDATION: {'âœ… PASS' if overall_success else 'âŒ FAIL'}")
    
    return overall_success

def test_mixed_content():
    """Test parsing of mixed content that includes both valid metrics and invalid content."""
    
    print("\nğŸ§ª Testing Mixed Content Parsing")
    print("=" * 45)
    
    # Simulate a medical report with mixed content
    mixed_content = """
Ğ”Ğ°Ñ‚Ğ°: 26.04.2025
Ğ’Ñ€ĞµĞ¼Ñ: 16:12
ĞŸĞ°Ñ†Ğ¸ĞµĞ½Ñ‚: Ğ˜Ğ²Ğ°Ğ½Ğ¾Ğ² Ğ˜.Ğ˜.
ĞĞ±Ñ‰Ğ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· ĞºÑ€Ğ¾Ğ²Ğ¸:

HGB: 163.00 Ğ³/Ğ» (Ğ½Ğ¾Ñ€Ğ¼Ğ°: 130,00 - 160,00)
RBC: 5.66 10^12/Ğ» (Ğ½Ğ¾Ñ€Ğ¼Ğ°: 4,50 - 5,90)
26.04.2025_16: 12
Ğ›Ğ¸Ğ¼Ñ„Ğ¾Ñ†Ğ¸Ñ‚Ñ‹ (Ğ°Ğ±Ñ: ĞºĞ¾Ğ»-Ğ²Ğ¾): 4
PLT: 319.00 10^9/Ğ» (Ğ½Ğ¾Ñ€Ğ¼Ğ°: 180,00 - 320,00)
WBC: 6.37 10^9/Ğ» (Ğ½Ğ¾Ñ€Ğ¼Ğ°: 4,00 - 9,00)
14: 19
MCV: 83.20 Ñ„Ğ» (Ğ½Ğ¾Ñ€Ğ¼Ğ°: 80,00 - 100,00)
MCH: 28.80 Ğ¿Ğ³ (Ğ½Ğ¾Ñ€Ğ¼Ğ°: 27,00 - 32,00)
Ğ—Ğ°ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ: Ğ² Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ°Ñ… Ğ½Ğ¾Ñ€Ğ¼Ñ‹
"""
    
    print("ğŸ“„ Raw mixed content:")
    print("-" * 30)
    print(mixed_content.strip())
    print("-" * 30)
    
    try:
        metrics = ocr_service.extract_metrics_from_text(mixed_content)
        
        print(f"\nğŸ“Š Extracted {len(metrics)} valid metrics:")
        print("=" * 50)
        
        # Expected valid metrics from the mixed content
        expected_metrics = ['HGB', 'RBC', 'PLT', 'WBC', 'MCV', 'MCH']
        found_metrics = []
        
        for metric in metrics:
            original_name = metric.get('original_line', '').split(':')[0].strip().upper()
            found_metrics.append(original_name)
            confidence = metric.get('confidence', 0)
            status_icon = "ğŸŸ¢" if metric['status'] == 'normal' else "ğŸ”´"
            print(f"  {status_icon} {metric['name']:25} = {metric['value']:>8.2f} {metric['unit']:15} (conf: {confidence:.2f})")
            print(f"     Original: {metric.get('original_line', 'N/A')}")
        
        # Check if we got the expected metrics and avoided the problematic ones
        expected_found = sum(1 for exp in expected_metrics if exp in found_metrics)
        
        # Check that we didn't extract the problematic lines
        problematic_lines = ['26.04.2025_16', '14', 'Ğ›Ğ¸Ğ¼Ñ„Ğ¾Ñ†Ğ¸Ñ‚Ñ‹ (Ğ°Ğ±Ñ', 'Ğ”Ğ°Ñ‚Ğ°', 'Ğ’Ñ€ĞµĞ¼Ñ', 'Ğ—Ğ°ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ']
        problematic_found = sum(1 for prob in problematic_lines if any(prob.lower() in metric['name'].lower() for metric in metrics))
        
        print(f"\nğŸ“ˆ Analysis:")
        print(f"   Expected metrics found: {expected_found}/{len(expected_metrics)}")
        print(f"   Problematic content avoided: {len(problematic_lines) - problematic_found}/{len(problematic_lines)}")
        
        success = (expected_found >= len(expected_metrics) * 0.8) and (problematic_found == 0)
        print(f"\nğŸ¯ Mixed Content Test: {'âœ… PASS' if success else 'âŒ FAIL'}")
        
        return success
        
    except Exception as e:
        print(f"âŒ Error processing mixed content: {e}")
        return False

def test_edge_cases():
    """Test edge cases for validation."""
    
    print("\nğŸ”¬ Testing Edge Cases")
    print("=" * 30)
    
    edge_cases = [
        # Borderline cases that could go either way
        {"text": "Ğ¡ĞĞ­: 15 Ğ¼Ğ¼/Ñ‡Ğ°Ñ", "should_accept": True, "description": "Valid ESR metric"},
        {"text": "Ğ’Ğ¾Ğ·Ñ€Ğ°ÑÑ‚: 25 Ğ»ĞµÑ‚", "should_accept": False, "description": "Age is not a lab metric"},
        {"text": "T: 36.6 Â°C", "should_accept": True, "description": "Temperature with proper unit"},
        {"text": "ID: 12345", "should_accept": False, "description": "Patient ID"},
        {"text": "pH: 7.4 ĞµĞ´", "should_accept": True, "description": "pH value"},
        {"text": "ĞšĞ°Ğ±Ğ¸Ğ½ĞµÑ‚: 101", "should_accept": False, "description": "Room number"},
    ]
    
    success_count = 0
    for case in edge_cases:
        try:
            metrics = ocr_service.extract_metrics_from_text(case["text"])
            actually_accepted = len(metrics) > 0
            
            if actually_accepted == case["should_accept"]:
                status = "âœ… CORRECT"
                success_count += 1
            else:
                status = "âŒ WRONG"
            
            expected = "ACCEPT" if case["should_accept"] else "REJECT"
            actual = "ACCEPTED" if actually_accepted else "REJECTED"
            
            print(f"{status} {case['text']:20} | Expected: {expected:6} | Actual: {actual:8} | {case['description']}")
            
        except Exception as e:
            print(f"âŒ ERROR {case['text']:20} | {e}")
    
    edge_success = success_count == len(edge_cases)
    print(f"\nğŸ“Š Edge Cases: {success_count}/{len(edge_cases)} ({success_count/len(edge_cases)*100:.1f}%)")
    print(f"ğŸ¯ Edge Case Test: {'âœ… PASS' if edge_success else 'âŒ FAIL'}")
    
    return edge_success

if __name__ == "__main__":
    print("ğŸš€ Enhanced Validation Test Suite")
    print("=" * 80)
    
    # Run all validation tests
    test1_result = test_validation_filtering()
    test2_result = test_mixed_content()
    test3_result = test_edge_cases()
    
    # Final summary
    print("\n" + "=" * 80)
    print("ğŸ“Š VALIDATION TEST RESULTS:")
    print(f"  Basic Filtering Test:   {'âœ… PASS' if test1_result else 'âŒ FAIL'}")
    print(f"  Mixed Content Test:     {'âœ… PASS' if test2_result else 'âŒ FAIL'}")
    print(f"  Edge Cases Test:        {'âœ… PASS' if test3_result else 'âŒ FAIL'}")
    
    overall_success = test1_result and test2_result and test3_result
    print(f"\nğŸ¯ OVERALL: {'âœ… ENHANCED VALIDATION WORKING' if overall_success else 'âŒ VALIDATION ISSUES REMAIN'}")
    
    if overall_success:
        print("\nğŸ‰ SUCCESS: Enhanced validation is working correctly!")
        print("   â€¢ Timestamps and dates are properly filtered out")
        print("   â€¢ Section headers are not treated as metrics")
        print("   â€¢ Valid medical metrics are still extracted")
        print("   â€¢ Scientific notation parsing is preserved")
    else:
        print("\nâš ï¸  Some validation issues remain - see details above")
    
    print("=" * 80) 